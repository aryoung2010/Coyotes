---
title: "Analysis and Visualization"
author: "Frank"
date: "11/11/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(zipcode)
library(tidyverse)
library(usmap)
library(ggplot2)
library(tidytext)
library(tm)
library(topicmodels)
library(wordcloud)
library(RColorBrewer)
library(sentimentr)
library(lme4)
```

```{r}
# Reading samples
sample <- read.csv("Real_Talk_Data.csv", stringsAsFactors = FALSE)
sample <- sample[1:812,]
colnames(sample)[13] <- "zip"
sample$zip[sample$zip < 10000 & is.na(sample$zip) == F] <- 
  sprintf("%05d", sample$zip[sample$zip < 10000 & is.na(sample$zip) == F])
sample <- sample[ , colSums(!is.na(sample)) != 0]
sample$Story <- do.call(paste, c(sample[18:127], sep=" "))
sample <- sample[,c(1:17,128)]

# Clean up
sample$LGBTQ.[sample$LGBTQ. == "" | is.na(sample$LGBTQ.) == T] <- "Prefer not to share"
sample$LGBTQ.[sample$LGBTQ. == "nyes" | sample$LGBTQ. == "yes "] <- "yes"
sample$LGBTQ.[sample$LGBTQ. == "on"] <- "no"
sample$Gender[sample$Gender == "" | is.na(sample$Gender) == T] <- "Prefer not to share"
sample$Gender[sample$Gender == "abstain" | sample$Gender == "abstain "] <- "Prefer not to share"
sample$Gender[sample$Gender == "Female"] <- "female"
sample$Gender[sample$Gender == "Male" | sample$Gender == "male "] <- "male"
sample$Gender[sample$Gender == "Other" | sample$Gender == "non-binary" | sample$Gender == "Non-binary"] <- "other"
```

```{r}
# sentiment_score <- sentiment(realtalk$Story) %>% 
#   group_by(element_id) %>% 
#   summarise(sentiment = sum(sentiment))
realtalk$sentiment <- sentiment_by(realtalk$Story)[,4]
realtalk$sentiment <- apply(realtalk$sentiment,2,as.numeric)
regdata <- realtalk[c(-3,-10,-11,-17,-131,-133,-272,-411,-449,-614,-622,-769,-777,-806), c(1,19,4,10:12,17:18,20)]
```


```{r}
# Creating Tidytext and Corpus objects
# Using Tidytext to unnest the dataframe
realtalkdf <- realtalk %>% 
  select(Story) %>% 
  unnest_tokens("word", Story)
# Stopwords
data("stop_words")
realtalksort <- realtalkdf %>% 
  anti_join(stop_words) %>% 
  count(word) %>% 
  arrange(desc(n))
# Creating Corpus
realtalk_corpus <- Corpus(VectorSource(as.vector(realtalk$Story))) 
realtalk_corpus <- tm_map(realtalk_corpus, removeWords, stopwords("english"))
realtalk_corpus <- tm_map(realtalk_corpus, content_transformer(removeNumbers))
realtalk_corpus <- tm_map(realtalk_corpus, content_transformer(removePunctuation))
realtalk_corpus <- tm_map(realtalk_corpus, content_transformer(tolower))
realtalk_corpus <- tm_map(realtalk_corpus, content_transformer(stemDocument), language = "english")
# Creating dtm
DTM <- DocumentTermMatrix(realtalk_corpus, control = list(wordLengths = c(2, Inf)))
TDM <- TermDocumentMatrix(realtalk_corpus, control = list(wordLengths = c(2, Inf)))
```

```{r}
# Graphing1: top 20 words in histogram
top_20 <- realtalksort[1:20,]
top_20$word <- factor(top_20$word,
                      levels = top_20$word[order(top_20$n, decreasing = TRUE)])
ggplot(top_20, aes(x=word, y=n, fill=word))+
  geom_bar(stat="identity")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  ylab("Word freq in real talks sample")+
  xlab("")+
  guides(fill=FALSE)
```

```{r}
# Graphing2: Corpus & Topic modeling
rowTotals <- apply(DTM, 1, sum)
DTM <- DTM[rowTotals >0, ]
topic_model<-LDA(DTM, k=10, control = list(seed = 321))
# Tidying the model
topics <- tidy(topic_model, matrix = "beta")
top_terms <- 
  topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
# Ploting 
top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```

```{r}
# Graphing3: Wordcloud
m <- as.matrix(TDM)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
# head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

```{r}
# Graphing4: visualization of state counts for the sample
# Building a zipprefix-state df
data(zipcode)
zip <- zipcode %>% 
  select(zip, state) %>% 
  distinct(zip, .keep_all = TRUE)
# Creat a new df with state and state count
samplestate <- merge(sample, zip, by = "zip")
samplecount <- samplestate %>% 
  group_by(state) %>% 
  count(state)
# Plotting
plot_usmap(regions = "states", data = samplecount, values = "n", lines = "grey") + 
  scale_fill_continuous(low = "white", high = "red", name = "Story Population", label = scales::comma) +
  labs(title = "Real Talk Sample Density in US") + 
  theme(panel.background = element_rect(colour = "black", fill = "white"), legend.position = "right")
```

```{r}
# Graphing5: visualization of mean sentiment score on different states
sentimentmean <- regdata %>% 
  group_by(state) %>% 
  summarise(mean_sent = 10*mean(sentiment, na.rm = T))
sentimentmean <- merge(sentimentmean, samplecount, by = "state")
sentimentmean$red <- 0
sentimentmean$red[c(1:3,5,7,8,10,11,13:16,19:28,33,34,36,38:42,44:46)] <- 1
# Plotting
plot_usmap(regions = "states", data = sentimentmean, values = "mean_sent", lines = "grey") + 
  scale_fill_continuous(low = "red", high = "white", name = "Sentiment_Score", label = scales::comma) +
  labs(title = "Real Talk Sample Sentiment in US") + 
  theme(panel.background = element_rect(colour = "black", fill = "white"), legend.position = "right")
```

# Election and realtalk regression:
```{r}
plot_usmap(regions = "states", data = sentimentmean, values = "red", lines = "white") + 
  scale_fill_continuous(low = "blue", high = "red", name = "Results for 2016 election", label = scales::comma) +
  labs(title = "Real Talk Sample Sentiment in US") + 
  theme(panel.background = element_rect(colour = "black", fill = "white"), legend.position = "right")
```

```{r}
# Create a new column of state with zip
regdata <- merge(regdata, sentimentmean[,c(1,4)], by = "state", all.x = TRUE)
regdata$Gender <- as.factor(regdata$Gender)
regdata$LGBTQ. <- as.factor(regdata$LGBTQ.)
regdata$Submission..Type <- as.factor(regdata$Submission..Type)
regdata$Subject <- as.factor(regdata$Subject)
names(regdata)[9]<-"sentiment"
regdata$wordcount <- str_count(regdata$Story, '\\w+')
plot(sentiment~Age, data = regdata)
plot(sentiment~Gender, data = regdata)
plot(sentiment~LGBTQ., data = regdata)
plot(sentiment~Subject, data = regdata)
plot(sentiment~Submission..Type, data = regdata)
plot(sentiment~wordcount, data = regdata)
hist(regdata$sentiment, breaks =20)
```

```{r}
reg <- lm(sentiment ~ Age + Gender + LGBTQ. + Subject + Submission..Type + wordcount + red, data = regdata)
summary(reg)
```














